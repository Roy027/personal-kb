import sys
import os

# Add project root to sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../..")))

import streamlit as st
import time
import pandas as pd
from typing import List
from src.kb.rag.answer import AnswerEngine
from src.kb.schema import Document
from src.kb.chunking.chunker import Chunker
from src.kb.ingestion.pdf_loader import load_pdf
from src.kb.ingestion.html_loader import load_html

# Page Config
st.set_page_config(
    page_title="Local KB RAG",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- CSS Styling ---
st.markdown("""
<style>
    .chat-message {
        padding: 1.5rem; border-radius: 0.5rem; margin-bottom: 1rem; display: flex
    }
    .chat-message.user {
        background-color: #2b313e; color: #ffffff;
    }
    .chat-message.bot {
        background-color: #f0f2f6; color: #000000;
    }
</style>
""", unsafe_allow_html=True)

# --- Helpers ---

LOADERS = {
    ".pdf": load_pdf,
    ".html": load_html,
    ".htm": load_html
}

def save_uploaded_file(uploaded_file):
    save_dir = "./data/raw"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    file_path = os.path.join(save_dir, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path

def ingest_file(file_path, engine):
    """
    Ingests a single file into the active vector store.
    """
    ext = os.path.splitext(file_path)[1].lower()
    if ext not in LOADERS:
        st.error(f"Unsupported file format: {ext}")
        return

    # 1. Load (åŠ è½½)
    status = st.empty()
    progress = st.progress(0)
    
    status.write(f"ğŸ“„ æ­£åœ¨åŠ è½½æ–‡æ¡£ï¼š{os.path.basename(file_path)}...")
    loader = LOADERS[ext]
    documents = loader(file_path)
    progress.progress(30)
    
    if not documents:
        st.warning("æœªæ£€æµ‹åˆ°æ–‡æœ¬å†…å®¹ã€‚")
        return

    # 2. Chunk (åˆ‡åˆ†)
    status.write(f"âœ‚ï¸ æ­£åœ¨åˆ‡åˆ† {len(documents)} é¡µå†…å®¹...")
    chunker = Chunker()
    chunked_docs = chunker.split_documents(documents)
    progress.progress(60)

    # 3. Embed & Index (å‘é‡åŒ–)
    status.write(f"ğŸ§  æ­£åœ¨ç”Ÿæˆå‘é‡ (å…± {len(chunked_docs)} ä¸ªåˆ‡ç‰‡ï¼ŒCPU æ¨¡å¼è¯·ç¨å€™)...")
    
    # Access internal components from engine
    # structure: engine -> retriever -> embedder/vector_store
    embedder = engine.retriever.embedder
    vector_store = engine.retriever.vector_store
    
    embeddings = embedder.embed_documents(chunked_docs)
    progress.progress(90)
    
    status.write("ğŸ’¾ ä¿å­˜ç´¢å¼•ä¸­...")
    vector_store.add_documents(chunked_docs, embeddings)
    vector_store.save()
    progress.progress(100)
    
    status.success(f"æˆåŠŸå¤„ç†æ–‡æ¡£ï¼š{os.path.basename(file_path)}ï¼")
    time.sleep(1)
    status.empty()
    progress.empty()

@st.cache_resource(show_spinner="æ­£åœ¨åŠ è½½ RAG å¼•æ“...")
def get_engine(model_name: str):
    return AnswerEngine(index_path="./data/index", llm_model=model_name)

# --- Sidebar ---
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
    
    st.markdown("### æ¨¡å‹é…ç½®")
    llm_model = st.selectbox("LLM æ¨¡å‹", ["qwen3:8b", "llama3:8b"], index=0)
    
    st.markdown("### æ£€ç´¢å‚æ•°")
    top_k = st.slider("åˆç­›æ•°é‡ (Recall Top-K)", 5, 50, 20)
    top_n = st.slider("ç²¾æ’æ•°é‡ (Rerank Top-N)", 1, 10, 3)
    
    st.markdown("---")
    if st.button("æ¸…ç©ºå¯¹è¯è®°å½•", type="primary"):
        st.session_state.messages = []
        st.rerun()
        
    st.markdown("---")
    st.caption("v0.2.1 | Local Knowledge Base")

# --- Initial Load ---
try:
    engine = get_engine(llm_model)
except Exception as e:
    st.error(f"å¼•æ“åŠ è½½å¤±è´¥: {e}")
    st.stop()

# --- Main Interface ---
st.title("ğŸ“š æœ¬åœ°çŸ¥è¯†åº“åŠ©æ‰‹")

# -----------------------------------------------------------------------------
# Dynamic Sidebar File Filter using Engine
with st.sidebar:
    st.markdown("### ğŸ“š çŸ¥è¯†åº“èŒƒå›´")
    
    selected_files = None # Default to None = All
    
    if hasattr(engine.retriever.vector_store, 'get_indexed_files'):
        files_data = engine.retriever.vector_store.get_indexed_files()
        # files_data = [{'filename': 'x.pdf', 'chunks': 10}, ...]
        
        if files_data:
            all_filenames = [f['filename'] for f in files_data]
            
            # Session State for Persistence
            if "file_states" not in st.session_state:
                st.session_state.file_states = {}
            
            # Sync: New files default to True
            for f in all_filenames:
                if f not in st.session_state.file_states:
                    st.session_state.file_states[f] = True
            
            # Build DataFrame from State
            df_data = []
            for f_data in files_data:
                fname = f_data['filename']
                is_selected = st.session_state.file_states.get(fname, True)
                df_data.append({
                    "å¯ç”¨": is_selected,
                    "æ–‡ä»¶å": fname,
                    "åˆ‡ç‰‡": f_data['chunks']
                })
            
            df_filter = pd.DataFrame(df_data)
            
            with st.expander(f"é€‰æ‹©æ–‡ä»¶ ({len(all_filenames)})", expanded=False):
                edited_df = st.data_editor(
                    df_filter,
                    column_config={
                        "å¯ç”¨": st.column_config.CheckboxColumn(required=True),
                        "æ–‡ä»¶å": st.column_config.TextColumn(disabled=True),
                        "åˆ‡ç‰‡": st.column_config.NumberColumn(disabled=True)
                    },
                    hide_index=True,
                    use_container_width=True,
                    key="file_filter_editor"
                )
            
            # Update State & Get Selected
            selected_files = []
            for index, row in edited_df.iterrows():
                fname = row["æ–‡ä»¶å"]
                is_active = row["å¯ç”¨"]
                st.session_state.file_states[fname] = is_active
                if is_active:
                    selected_files.append(fname)
            
            st.caption(f"å·²é€‰ {len(selected_files)} / {len(all_filenames)} ä¸ªæ–‡æ¡£")

# -----------------------------------------------------------------------------

tab1, tab2 = st.tabs(["ğŸ’¬ æ™ºèƒ½é—®ç­”", "ğŸ—ƒï¸ çŸ¥è¯†åº“ç®¡ç†"])

# === TAB 1: CHAT ===
with tab1:
    # Initialize Msg
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display History
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if "sources" in msg and msg["sources"]:
                with st.expander("ğŸ“š æŸ¥çœ‹å¼•ç”¨æ¥æº"):
                    for i, doc in enumerate(msg["sources"], 1):
                        source = os.path.basename(doc.metadata.get("source", "æœªçŸ¥æ¥æº"))
                        page = doc.metadata.get("page_number", "-")
                        score = doc.metadata.get("rerank_score", 0.0)
                        st.markdown(f"**{i}. {source}** (é¡µç : {page}, ç›¸å…³åº¦: {score:.4f})")
                        st.caption(doc.content[:300] + "...")

    # Chat Input
    if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨æ€è€ƒä¸æ£€ç´¢..."):
                answer, sources = engine.answer(prompt, top_k=top_k, top_n=top_n, file_filters=selected_files)
            
            st.markdown(answer)
            
            if sources:
                with st.expander("ğŸ“š æŸ¥çœ‹å¼•ç”¨æ¥æº"):
                    for i, doc in enumerate(sources, 1):
                        source = os.path.basename(doc.metadata.get("source", "æœªçŸ¥æ¥æº"))
                        page = doc.metadata.get("page_number", "-")
                        score = doc.metadata.get("rerank_score", 0.0)
                        st.markdown(f"**{i}. {source}** (é¡µç : {page}, ç›¸å…³åº¦: {score:.4f})")
                        st.caption(doc.content)
            
            st.session_state.messages.append({"role": "assistant", "content": answer, "sources": sources})

# === TAB 2: KNOWLEDGE BASE ===
with tab2:
    st.header("æ–‡æ¡£ç®¡ç†")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“‚ å·²æ”¶å½•æ–‡æ¡£")
        # Get file stats
        if hasattr(engine.retriever.vector_store, 'get_indexed_files'):
            files_data = engine.retriever.vector_store.get_indexed_files()
            if files_data:
                df = pd.DataFrame(files_data).rename(columns={"filename": "æ–‡ä»¶å", "chunks": "åˆ‡ç‰‡æ•°é‡"})
                st.dataframe(df, use_container_width=True)
                st.caption(f"å½“å‰æ€»æ–‡æ¡£æ•°: {len(df)}")
            else:
                st.info("æš‚æ— å·²ç´¢å¼•çš„æ–‡æ¡£ã€‚")
        else:
            st.warning("VectorStore æœªå®ç° 'get_indexed_files' åŠŸèƒ½ã€‚")

    with col2:
        st.subheader("â¬†ï¸ ä¸Šä¼ æ–°æ–‡æ¡£")
        uploaded_file = st.file_uploader("é€‰æ‹© PDF æˆ– HTML æ–‡ä»¶", type=["pdf", "html"])
        
        if uploaded_file:
            if st.button("å¼€å§‹å¯¼å…¥", type="primary"):
                try:
                    # Save
                    file_path = save_uploaded_file(uploaded_file)
                    # Ingest
                    ingest_file(file_path, engine)
                    st.rerun() # Refresh list
                except Exception as e:
                    st.error(f"å¯¼å…¥å¤±è´¥: {e}")
